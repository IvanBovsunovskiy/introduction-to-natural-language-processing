{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW7.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f-VeVf9esBFE",
        "tniuHWtPu1f5",
        "DZlQkGVm1t5Q",
        "YYnH0iVd1x4k",
        "G8-U0F932dio",
        "KBta-b662k4F",
        "9eHK0K1Lw6nb",
        "qEyvOxoOJDTP"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Урок 7. Сверточные нейронные сети для анализа текста\n",
        "Задание\n",
        "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
        "1. Учим conv сеть для классификации\n",
        "2. Рассмотреть 2-а варианта сеточек\n",
        "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
        "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
        "\n",
        "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
      ],
      "metadata": {
        "id": "XcKIApx6rN6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 300\n",
        "num_classes = 5\n",
        "\n",
        "# Training\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ],
      "metadata": {
        "id": "ZSogMlstw95K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports, data load"
      ],
      "metadata": {
        "id": "f-VeVf9esBFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words -q\n",
        "!pip install pymorphy2 -q"
      ],
      "metadata": {
        "id": "DiKC6jpjsDG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade xlrd"
      ],
      "metadata": {
        "id": "wiUXNmJytB2y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show xlrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzQPiN37tofq",
        "outputId": "41fe169b-5e24-499f-9f83-ed852edff188"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: xlrd\n",
            "Version: 2.0.1\n",
            "Summary: Library for developers to extract data from Microsoft Excel (tm) .xls spreadsheet files\n",
            "Home-page: http://www.python-excel.org/\n",
            "Author: Chris Withers\n",
            "Author-email: chris@withers.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "metadata": {
        "id": "pmiLL-SNsD4J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.pandas.read_excel(\"отзывы за лето.xls\")"
      ],
      "metadata": {
        "id": "7gbTXzlBsQFY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCFUXxAut8oy",
        "outputId": "cfbcbbfd-48f7-4cad-9e26-33a9d81237d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20659 entries, 0 to 20658\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Rating   20659 non-null  int64 \n",
            " 1   Content  20656 non-null  object\n",
            " 2   Date     20659 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 484.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "clzvzDvguPlw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Rating.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xtHZtoauaTu",
        "outputId": "6fef49b3-cbe8-4cb3-b00c-6d5a175c2e0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 4, 2, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_temp, df_test = train_test_split(df, test_size=0.2, random_state=12)\n",
        "df_train, df_val = train_test_split(df_train_temp, test_size=0.2, random_state=12)\n",
        "df_train_temp = None"
      ],
      "metadata": {
        "id": "PKq-YDX3vQ5H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "tniuHWtPu1f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
        "df_val['Content'] = df_val['Content'].apply(preprocess_text)\n",
        "df_test['Content'] = df_test['Content'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Ygiyg5Gqu0Wp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rating preprocessing 1 - class 0, 5 - class 4\n",
        "df_train['Rating'] = df_train['Rating'] - 1\n",
        "df_val['Rating'] = df_val['Rating'] - 1\n",
        "df_test['Rating'] = df_test['Rating'] - 1"
      ],
      "metadata": {
        "id": "VPcmdibp0q4k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(df_train[\"Content\"])\n",
        "train_corpus = train_corpus.lower()"
      ],
      "metadata": {
        "id": "tnRcgBUpwq86"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbs0aJdwmQw",
        "outputId": "25ee47d4-842e-4921-ba50-c01db940f3ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "ZUlBtajfwzxy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ],
      "metadata": {
        "id": "MaNEiOh8w1Ld"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "metadata": {
        "id": "S0ThHgoDxZ6F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ],
      "metadata": {
        "id": "WsmEMI7YxgAO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Content\"]], dtype=np.int32)"
      ],
      "metadata": {
        "id": "-AfXB4Ldxs9m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, x_test.shape, "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aNRtxolx4Os",
        "outputId": "d0f038bb-40e0-43e8-84b0-a6370b311072"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13219, 300), (3305, 300), (4132, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Net"
      ],
      "metadata": {
        "id": "31RkfnXmzndE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "DZlQkGVm1t5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "y_train = keras.utils.to_categorical(df_train[\"Rating\"], num_classes)\n",
        "y_val = keras.utils.to_categorical(df_val[\"Rating\"], num_classes)\n",
        "y_test = keras.utils.to_categorical(df_test[\"Rating\"], num_classes)"
      ],
      "metadata": {
        "id": "P_W-5q0nzmnU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=300, input_length=max_len))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "TqSv7U2e1gkh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fBCKPptW1r9T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model fit"
      ],
      "metadata": {
        "id": "YYnH0iVd1x4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg-f1DL91zr5",
        "outputId": "a7bc6e01-582a-4f4c-bc83-55cf7cbb571c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 79s 3s/step - loss: 1.0552 - accuracy: 0.6870 - val_loss: 0.8569 - val_accuracy: 0.7020\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 72s 3s/step - loss: 0.7547 - accuracy: 0.7344 - val_loss: 0.7214 - val_accuracy: 0.7576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model evaluate"
      ],
      "metadata": {
        "id": "G8-U0F932dio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Validation score:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh0GI6Dh2dxJ",
        "outputId": "017a9283-b009-4e6e-eaad-257210e34365"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 624ms/step - loss: 0.7214 - accuracy: 0.7576\n",
            "\n",
            "\n",
            "Validation score: 0.7213513851165771\n",
            "Validation accuracy: 0.7576399445533752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJzFxwc2F0bz",
        "outputId": "76e29d2b-294a-463f-b455-97c7b8402ba5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 6s 614ms/step - loss: 0.7316 - accuracy: 0.7575\n",
            "\n",
            "\n",
            "Test score: 0.7316172122955322\n",
            "Test accuracy: 0.7575024366378784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy on test data"
      ],
      "metadata": {
        "id": "KBta-b662k4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0wCqW8q2tYj",
        "outputId": "85a93524-a8f2-4d54-f7fb-2b199d1f7787"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 6s 613ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [np.argmax(item) for item in results]"
      ],
      "metadata": {
        "id": "Gcqk1ZPwE0s2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(df_test['Rating'].to_numpy(), result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL79aGQ93Dto",
        "outputId": "07c33ace-56c4-44c9-96a8-53152a7e97f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7575024201355276"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RusVectors net"
      ],
      "metadata": {
        "id": "M01BtYKm34Pe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data downloading & processing\n",
        "\n",
        "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
      ],
      "metadata": {
        "id": "d4zB12_2M9kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'http://vectors.nlpl.eu/repository/20/220.zip' -q -N"
      ],
      "metadata": {
        "id": "6eFPMGHz39PO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq -o 220.zip "
      ],
      "metadata": {
        "id": "-Vcqh1Jq4xLq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_conversion(line):\n",
        "  data_list = line.split()\n",
        "  data = []\n",
        "  word = None\n",
        "  for field in data_list:\n",
        "    try:\n",
        "      data.append(float(field))\n",
        "    except ValueError:\n",
        "      word = field.split('_')[0]\n",
        "  return word, data"
      ],
      "metadata": {
        "id": "1IGhMWR6RTcK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_matrix = pd.read_csv('model.txt', sep=' ')"
      ],
      "metadata": {
        "id": "L8BPPc3YOoVe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.txt', 'r') as f:\n",
        "  embedding_matrix = None\n",
        "  word_dict = []\n",
        "  for line in f:\n",
        "    word, embedding_vector = line_conversion(line)\n",
        "    if word in vocabulary.keys():\n",
        "      word_dict.append(word)\n",
        "      if embedding_matrix is None:\n",
        "        embedding_matrix = np.array(embedding_vector)\n",
        "      else:\n",
        "        embedding_matrix = np.concatenate((embedding_matrix, embedding_vector))\n",
        "    if len(word_dict) == max_words:\n",
        "      break"
      ],
      "metadata": {
        "id": "x1omF1BsNCF2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix=np.reshape(embedding_matrix,(max_words, max_len))"
      ],
      "metadata": {
        "id": "R63u8vp5Rnt0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word_dic = pd.read_csv('word.dic', names=['word', 'position'], sep='\\t' , error_bad_lines=False)"
      ],
      "metadata": {
        "id": "q0Cp8GHBP6u_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "3NEiGPXhcS7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                    output_dim=embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_len,\n",
        "                    trainable=False))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "NFMgMsTicUxQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jXicMzGBSsuo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model fit"
      ],
      "metadata": {
        "id": "OO9w463TSg1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du_Irl2ySigL",
        "outputId": "fb7998c6-85ad-49a3-cb73-f69b5659c811"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 53s 2s/step - loss: 0.9978 - accuracy: 0.6750 - val_loss: 0.7879 - val_accuracy: 0.6980\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 52s 2s/step - loss: 0.7385 - accuracy: 0.7302 - val_loss: 0.7593 - val_accuracy: 0.7165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model evaluate"
      ],
      "metadata": {
        "id": "x63BkO_fS5Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Validation score:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CmDD52yS7Qm",
        "outputId": "bcaff735-7b52-4785-b34f-0d5dbd91681c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 631ms/step - loss: 0.7593 - accuracy: 0.7165\n",
            "\n",
            "\n",
            "Validation score: 0.7593154311180115\n",
            "Validation accuracy: 0.7164901494979858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbaX3bw9S771",
        "outputId": "3b3c6c28-d500-48e1-bd4e-15b0fe6af2fd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 6s 618ms/step - loss: 0.7748 - accuracy: 0.7212\n",
            "\n",
            "\n",
            "Test score: 0.7747810482978821\n",
            "Test accuracy: 0.7212004065513611\n"
          ]
        }
      ]
    }
  ]
}